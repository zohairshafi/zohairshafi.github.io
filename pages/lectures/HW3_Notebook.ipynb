{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd36a98f",
   "metadata": {},
   "source": [
    "# Homework 3 \n",
    "This homework will walk you through logistic regression implementation and evaluation, followed by a bunch of theoretical and implementation based questions that you can treat as a practice problem set for the modeterms. \n",
    "\n",
    "Due Date - Friday 6th March (11:59 PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6e47b",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a3e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(42)  # reproducible randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad980163",
   "metadata": {},
   "source": [
    "# Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ac88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Classification Data\n",
    "\n",
    "n = 100\n",
    "class_1_x_1 = rng.normal(loc=0.0, scale=1.0, size = n)\n",
    "class_1_x_2 = rng.normal(loc=1.0, scale=1.0, size = n)\n",
    "\n",
    "class_2_x_1 = rng.normal(loc=1.0, scale=1.0, size = 10 * n)\n",
    "class_2_x_2 = rng.normal(loc=2.0, scale=1.0, size = 10 * n)\n",
    "\n",
    "\n",
    "x_1 = np.concatenate([class_1_x_1, class_2_x_1])\n",
    "x_2 = np.concatenate([class_1_x_2, class_2_x_2])\n",
    "y = np.concatenate([np.zeros(n), np.ones(10 * n)])\n",
    "\n",
    "X = np.vstack([x_1, x_2]).T\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_1, x_2, c = y, alpha=0.5)\n",
    "plt.xlabel('Input Feature $x_1$')\n",
    "plt.ylabel('Input Feature $x_2$')\n",
    "plt.title('Synthetic Classification Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb40d4f",
   "metadata": {},
   "source": [
    "# Question 1 - Logistic Regression via Gradient Descent (15 Points)\n",
    "\n",
    "In logistic regression we model the probability that a sample belongs to class 1 using the **sigmoid** function:\n",
    "\n",
    "$\\hat{y} = \\sigma(\\mathbf{\\theta_0} + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2) = \\frac{1}{1 + e^{-(\\theta_0 + \\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2)}}$\n",
    "\n",
    "where $\\mathbf{\\theta} = [\\theta_0, \\theta_1, \\theta_2]$ are the weights.\n",
    "\n",
    "We minimize the **Binary Cross-Entropy (BCE) Loss**:\n",
    "\n",
    "$L = -\\frac{1}{m}\\sum_{i=1}^{m} \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]$\n",
    "\n",
    "The gradients of the BCE loss with respect to the parameters are:\n",
    "\n",
    "$\\frac{\\partial L}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^{m} (\\hat{y}_i - y_i) \\cdot x_{ij}$ (Note: This equation works for both $\\theta_1$ and $\\theta_2$ but not for $\\theta_0$ which is the bias term)\n",
    "\n",
    "$\\frac{\\partial L}{\\partial \\theta_0} = \\frac{1}{m}\\sum_{i=1}^{m} (\\hat{y}_i - y_i)$\n",
    "\n",
    "Implement the `sigmoid` function, the `bce_loss` function, and complete `run_logistic_regression_gd` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbe2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############ Question 1(a) - 3 pts ###########\n",
    "###############################################\n",
    "\n",
    "# TODO: Implement the sigmoid function\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Compute the sigmoid of z.\"\"\"\n",
    "    return None # Your answer here\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"sigmoid(0)  = {sigmoid(0):.4f}  (expected 0.5)\")\n",
    "print(f\"sigmoid(10) = {sigmoid(10):.4f}  (expected ~1.0)\")\n",
    "print(f\"sigmoid(-10)= {sigmoid(-10):.4f}  (expected ~0.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab05187",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############ Question 1(b) - 2 pts ###########\n",
    "###############################################\n",
    "\n",
    "# TODO: Implement the Binary Cross-Entropy loss function\n",
    "# Hint: use a small epsilon (e.g. 1e-12) inside the log to avoid log(0)\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "def bce_loss(y_true, y_pred):\n",
    "    \"\"\"Compute Binary Cross-Entropy loss.\"\"\"\n",
    "    \n",
    "    # Some additional steps to ensure numerical stability\n",
    "    # This is important because log(0) is undefined and can cause issues when y_pred is exactly 0 or 1.\n",
    "    eps = 1e-12\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "\n",
    "    # Your answer here\n",
    "    return None\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "# Sanity check\n",
    "print(f\"BCE when predicting 0.9 for y=1: {bce_loss(np.array([1]), np.array([0.9])):.4f}\")\n",
    "print(f\"BCE when predicting 0.1 for y=1: {bce_loss(np.array([1]), np.array([0.1])):.4f}  (should be higher)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff72a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############ Question 1(c) - 10 pts ##########\n",
    "###############################################\n",
    "\n",
    "# TODO: Complete the gradient descent loop for logistic regression.\n",
    "# Fill in: the predicted probabilities (y_hat), the gradients for w and b,\n",
    "# and the parameter update steps.\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "def run_logistic_regression_gd(X, y, learning_rate=0.1, epochs=1000):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model using gradient descent.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray, shape (m, 2)  – feature matrix\n",
    "    y : np.ndarray, shape (m,)    – binary labels (0 or 1)\n",
    "    learning_rate : float\n",
    "    epochs : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : np.ndarray, shape (2,)  – learned weights\n",
    "    bias : float                   – learned bias\n",
    "    loss_history : list[float]  – BCE loss recorded every 50 iterations\n",
    "    \"\"\"\n",
    "    num_examples, num_features = X.shape\n",
    "\n",
    "    # Here, to make things a little more explicit, I'm using 'theta' for weights and 'bias' for bias,\n",
    "    # and computing gradients for both separately. \n",
    "    theta = np.zeros(num_features) # This is going to be of shape (2, 1). We have not included the bias term here because we are treating it separately.\n",
    "    bias = 0.0\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass: compute predicted probabilities\n",
    "        # Given the current parameters (theta and bias), compute the linear combination z (this should look similar to linear regression)\n",
    "        # and then apply sigmoid to get y_hat.\n",
    "        # Make sure you add the bias term to the product of input and theta before applying sigmoid.\n",
    "        \n",
    "        z = None # Your answer here\n",
    "        y_hat = None # Your answer here\n",
    "\n",
    "        # Compute gradients\n",
    "        grad_theta = None # Your answer here\n",
    "        grad_bias = None # Your answer here\n",
    "\n",
    "        # Update parameters\n",
    "        theta -= None # Your answer here\n",
    "        bias -= None # Your answer here\n",
    "\n",
    "        ################################################\n",
    "        ########## End of your answer ##################\n",
    "        ################################################\n",
    "\n",
    "        # Track loss periodically\n",
    "        if epoch % 50 == 0 or epoch == epochs - 1:\n",
    "            loss_history.append(bce_loss(y, y_hat))\n",
    "\n",
    "    return theta, bias, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e38782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and plot the loss curve for several learning rates\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(14, 5))\n",
    "\n",
    "for lr in [1, 0.1, 0.01, 0.001]:\n",
    "    theta, bias, loss_history = run_logistic_regression_gd(X, y, learning_rate = lr, epochs = 1000)\n",
    "    iters = list(range(0, 1000, 50)) + [999]\n",
    "    ax1.plot(iters, loss_history, marker=\"o\", markersize=3, label=f\"LR = {lr}\")\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"BCE Loss\")\n",
    "ax1.set_title(\"Training Loss Across Learning Rates\")\n",
    "ax1.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best learning rate to compute accuracy \n",
    "best_lr = 0.1\n",
    "theta, bias, loss_history = run_logistic_regression_gd(X, y, learning_rate=best_lr, epochs=1000)\n",
    "print(f\"Learned Weights: \\ntheta_1 = {theta[0]:.4f}\\ntheta_2 = {theta[1]:.4f}\\ntheta_0 (bias) = {bias:.4f}\\n\")\n",
    "\n",
    "# Compute training accuracy using a threshold of 0.5\n",
    "y_hat = None # Your answer here - you can use the same answer from above \n",
    "\n",
    "# Compute predicted classes based on the threshold\n",
    "y_pred_class = (y_hat >= 0.5).astype(int)\n",
    "accuracy = np.mean(y_pred_class == y)\n",
    "print(f\"Training Accuracy (Threshold = 0.5): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce0904",
   "metadata": {},
   "source": [
    "## Question 2 (6 points – 2 each)\n",
    "\n",
    "2(a): Why do we use **Binary Cross-Entropy** instead of **Mean Squared Error** as the loss function for logistic regression? What would happen if we used MSE with the sigmoid function?\n",
    "\n",
    "2(b): What happens to the training loss as you increase or decrease the learning rate? Which learning rate seems to work best and why?\n",
    "\n",
    "2(c): The sigmoid function outputs values between 0 and 1. What is the **interpretation** of these output values in the context of classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5649ff22",
   "metadata": {},
   "source": [
    "Enter your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdeb6bf",
   "metadata": {},
   "source": [
    "# Question 3 – Plotting the Decision Boundary (10 Points)\n",
    "\n",
    "The decision boundary of a logistic regression model is the set of points where $\\hat{y} = 0.5$, which corresponds to:\n",
    "\n",
    "$\\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\theta_0 = 0$\n",
    "\n",
    "For our two-feature case this becomes:\n",
    "\n",
    "$\\theta_1 \\cdot x_1 + \\theta_2 \\cdot x_2 + \\theta_0 = 0 \\quad\\Longrightarrow\\quad x_2 = -\\frac{\\theta_1 x_1 + \\theta_0}{\\theta_2}$\n",
    "\n",
    "Use the learned weights from Question 1 and plot:\n",
    "1. The original data points colored by class\n",
    "2. The decision boundary line overlaid on the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98855580",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############### Question 3 ####################\n",
    "################ 10 points ####################\n",
    "###############################################\n",
    "\n",
    "# TODO: Using the learned weights w and bias b from Question 1, \n",
    "# plot the decision boundary on top of the scatter plot of the data.\n",
    "# Hint: Solve for x_2 in terms of x_1 using the equation above.\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# Scatter the data points colored by class\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], alpha=0.5, label=\"Class 0\", edgecolors=\"k\", linewidths=0.3)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], alpha=0.5, label=\"Class 1\", edgecolors=\"k\", linewidths=0.3)\n",
    "\n",
    "# Decision boundary: x_2 = -(theta_1 * x_1 + theta_0) / theta_2\n",
    "# Use the equation for the decision boundary derived from the logistic regression model\n",
    "# to compute the corresponding x_2 values for a range of x_1 values.\n",
    "x1_range = np.linspace(X[:, 0].min() - 0.5, X[:, 0].max() + 0.5, 200)\n",
    "\n",
    "x2_boundary = None # Your answer here\n",
    "\n",
    "plt.plot(x1_range, x2_boundary, color=\"red\", linewidth=2, label=\"Decision Boundary\")\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "plt.xlabel(\"Input Feature $x_1$\")\n",
    "plt.ylabel(\"Input Feature $x_2$\")\n",
    "plt.title(\"Logistic Regression Decision Boundary\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ab2e3",
   "metadata": {},
   "source": [
    "## Question 4 (4 points – 2 each)\n",
    "\n",
    "4(a): The decision boundary is a straight line. Why is this the case for logistic regression? Could logistic regression ever produce a curved decision boundary on its own?\n",
    "\n",
    "4(b): Looking at the plot, are there data points on the \"wrong\" side of the boundary? What does that tell you about the separability of the two classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71dde2",
   "metadata": {},
   "source": [
    "Enter your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffdfe9",
   "metadata": {},
   "source": [
    "# Question 5 – Precision-Recall Curve (25 Points)\n",
    "\n",
    "Instead of using a fixed threshold of 0.5, we can vary the classification threshold $t \\in [0, 1]$ and compute **Precision** and **Recall** at each value.\n",
    "\n",
    "For a given threshold $t$, a sample is predicted as **positive** (class 1) if $\\hat{y} \\geq t$.\n",
    "\n",
    "Then:\n",
    "\n",
    "$\\text{Precision} = \\frac{TP}{TP + FP}$\n",
    "\n",
    "$\\text{Recall} = \\frac{TP}{TP + FN}$\n",
    "\n",
    "where:\n",
    "- **TP** (True Positives) = number of samples where $y = 1$ **and** $\\hat{y} \\geq t$\n",
    "- **FP** (False Positives) = number of samples where $y = 0$ **and** $\\hat{y} \\geq t$\n",
    "- **FN** (False Negatives) = number of samples where $y = 1$ **and** $\\hat{y} < t$\n",
    "\n",
    "Compute precision and recall for thresholds from 0 to 1 (in steps of 0.01) and plot the Precision-Recall curve.\n",
    "\n",
    "Also compute True Positive Rate and False Positive Rate to compute the Receiver Operator Characteristics Curve (ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############ Question 5(a) - 20 pts ##########\n",
    "###############################################\n",
    "\n",
    "# TODO: Using the predicted probabilities y_hat from your trained model,\n",
    "# loop over thresholds from 0 to 1 (step 0.01) and compute\n",
    "# precision, recall, tpr and fpr at each threshold. Store them in lists.\n",
    "# Handle the edge case where TP + FP = 0 (precision is undefined).\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "# Get predicted probabilities from the trained model\n",
    "# Use your code from above \n",
    "y_hat = None # Your answer here\n",
    "\n",
    "# Loop over all possible values of threhsholds between 0 and 1 (inclusive) with a step of 0.01\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "# Some lists to save computer values \n",
    "precisions = []\n",
    "recalls = []\n",
    "tprs = []\n",
    "fprs = []\n",
    "\n",
    "# Loop over thresholds \n",
    "for t in thresholds:\n",
    "\n",
    "    # Compute predicted classes based on the current threshold\n",
    "    y_pred_t = None # Your answer here\n",
    "    \n",
    "    # Compute TP, FP, FN, TN based on the predicted classes and true labels\n",
    "    TP = None # Your answer here\n",
    "    FP = None # Your answer here\n",
    "    FN = None # Your answer here\n",
    "    TN = None # Your answer here\n",
    "\n",
    "    # When you calculate precision, check to make sure the denominator\n",
    "    # is greater than 0. If it is not, set precision to 1.0 (since we have no false positives,\n",
    "    #  we can consider it perfect precision).\n",
    "    precision = None # Your answer here\n",
    "\n",
    "    # Similarly, when calculating recall, if the denominator is 0 (which means we have no true\n",
    "    #  positives and no false negatives), we can set recall to 0.0 since we have no true positives to recall.\n",
    "    recall = None # Your answer here\n",
    "\n",
    "    # Compute TPR and FPR for the current threshold\n",
    "    # Keep in mind the same issue as above when computing precision and recall. If the denominator is 0, you can set TPR to 0.0 \n",
    "    # (since we have no true positives to recall) and \n",
    "    # FPR to 0.0 (since we have no false positives).\n",
    "    TPR = None # Your answer here\n",
    "    FPR = None # Your answer here\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    tprs.append(TPR)\n",
    "    fprs.append(FPR)\n",
    "\n",
    "\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)\n",
    "tprs = np.array(tprs)\n",
    "fprs = np.array(fprs)\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "# Print a few sample values\n",
    "print(f\"{'Threshold':>10} {'Precision':>10} {'Recall':>10}\")\n",
    "print(\"-\" * 32)\n",
    "for idx in range(0, len(thresholds), 10):\n",
    "    print(f\"{thresholds[idx]:>10.2f} {precisions[idx]:>10.4f} {recalls[idx]:>10.4f}\")\n",
    "\n",
    "print ()\n",
    "\n",
    "# Print a few sample values\n",
    "print(f\"{'Threshold':>10} {'TPR':>10} {'FPR':>10}\")\n",
    "print(\"-\" * 32)\n",
    "for idx in range(0, len(thresholds), 10):\n",
    "    print(f\"{thresholds[idx]:>10.2f} {tprs[idx]:>10.4f} {fprs[idx]:>10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############ Question 5(b) - 2.5 pts ###########\n",
    "###############################################\n",
    "\n",
    "# TODO: Plot the Precision-Recall curve using the values you computed above.\n",
    "# X-axis should be Recall, Y-axis should be Precision.\n",
    "# Also plot the ROC Curve with FPR on the X-axis and TPR on the Y-axis.\n",
    "\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# Plot the Precision-Recall curve using the values you computed above.\n",
    "plt.plot(None, None, color=\"tab:blue\", linewidth=2)\n",
    "\n",
    "# Mark the threshold = 0.5 point\n",
    "idx_05 = np.argmin(np.abs(thresholds - 0.5))\n",
    "plt.scatter(recalls[idx_05], precisions[idx_05], color=\"red\", zorder=5, s=80, label=f\"Threshold = 0.5\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1.05])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# Plot the ROC Curve with FPR on the X-axis and TPR on the Y-axis.\n",
    "plt.plot(None, None, color=\"tab:blue\", linewidth=2)\n",
    "\n",
    "\n",
    "# Mark the threshold = 0.5 point\n",
    "idx_05 = np.argmin(np.abs(thresholds - 0.5))\n",
    "plt.scatter(fprs[idx_05], tprs[idx_05], color=\"red\", zorder=5, s=80, label=f\"Threshold = 0.5\")\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1.05])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f59a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############ Question 5(c) - 2.5 pts ##########\n",
    "###############################################\n",
    "\n",
    "# TODO: Plot the Precision-Recall and ROC curve \n",
    "# using the values computed from sklearn's built in functions for verification.\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve\n",
    "\n",
    "# Plot the same curves using sklearn's built in functions for verification\n",
    "plt.figure(figsize=(7, 5))\n",
    "precision_sk, recall_sk, _ = precision_recall_curve(y, y_hat)\n",
    "\n",
    "# Enter the right values to plot below\n",
    "plt.plot(None, None, color=\"tab:orange\", linestyle=\"--\", label=\"Precision-Recall\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(f\"Precision-Recall Curve (AUC: {average_precision_score(y, y_hat):.3f})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1.05])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "fpr_sk, tpr_sk, _ = roc_curve(y, y_hat)\n",
    "\n",
    "# Enter the right values to plot below\n",
    "plt.plot(None, None, color=\"tab:orange\", linestyle=\"--\", label=\"ROC\")\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(f\"ROC Curve (AUC: {roc_auc_score(y, y_hat):.3f})\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1.05])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146bbb6",
   "metadata": {},
   "source": [
    "# Question 6 (6 points - 2 each)\n",
    "\n",
    "Let us examine what the distribution of predicted probabilities looks like below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "ax1.set_title('(A) True Distribution of Classes 1 and 0')\n",
    "ax1.hist(y)\n",
    "ax1.set_xlabel('True Values')\n",
    "ax1.set_ylabel('Frequency of predictions')\n",
    "\n",
    "ax2.set_title('(B) Predicted Distribution of Probabilities')\n",
    "ax2.hist(y_hat, bins=100)\n",
    "ax2.axvline(threshold, color='red', linestyle='--', label=f'Threshold = {threshold}')\n",
    "ax2.set_xlabel('Predicted Values (After Sigmoid)')\n",
    "ax2.set_ylabel('Frequency of predictions')\n",
    "\n",
    "\n",
    "ax3.set_title('(C) Predicted Distribution of Classes after Threshold')\n",
    "ax3.hist((y_hat > threshold).astype(int))\n",
    "ax3.set_xlabel('Predicted Values (After Threshold)')\n",
    "ax3.set_ylabel('Frequency of predictions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7685a2",
   "metadata": {},
   "source": [
    "6(a): Look at plot (A). What does it tell you about the dataset? Is it an evenly split dataset? What metrics make sense for such a dataset? \n",
    "\n",
    "6(b): Look at plot (C). Play around with the threshold values. What happens when the threshold is set to a small value like 0.1? What about a large value like 0.99? \n",
    "\n",
    "6(c): Ideally you want plot (C), i.e., the **distribution** of predicted classes to look similar to plot (A), i.e., the **distribution** of true classes. How would you pick a threhsold that does this? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da853c0f",
   "metadata": {},
   "source": [
    "Enter your answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d54a28d",
   "metadata": {},
   "source": [
    "## Question 7 (24 points – 2 each)\n",
    "\n",
    "7(a): What happens to **Precision** as you increase the threshold from 0 to 1? What happens to **Recall**? Explain intuitively why they move in opposite directions.\n",
    "\n",
    "7(b): Imagine you are building a medical screening test where **missing a positive case is very costly**. Would you choose a high threshold or a low threshold? Would you prioritize precision or recall?\n",
    "\n",
    "7(c): Describe a real-world scenario where you would prefer **high precision over high recall**. Justify your answer.\n",
    "\n",
    "7(d): Give an example of an algorithm that does not have a closed-form solution and explain why one does not exist.\n",
    "\n",
    "7(e): Explain the difference between the validation dataset and the test dataset\n",
    "\n",
    "7(f): In K-Nearest Neighbors, if we increase K, how does bias change? How does variance change?\n",
    "\n",
    "7(g): Given a dataset, describe the steps needed to determine the optimal value of $\\lambda$\n",
    "\n",
    "7(h): Let X be a matrix with m rows and n columns. How would you find $\\theta$ to satisfy the equation $X\\theta = Y$? What could be a potential issue if you find that your solution is running into error or is very unstable?\n",
    "\n",
    "7(i) If a matrix is of shape (n x m) where m < n, then what is the maximum possible rank of the matrix?\n",
    "\n",
    "7(j): Given a fixed $\\theta$ when does a logistic regression predict “class 1” and when does it predict “class 0”?\n",
    "\n",
    "7(k): List one pro and one con of increasing the validation set from 20% of the original data to 30%?\n",
    "\n",
    "7(l): If you have a small amount of data and do not want to waste data on a test/validation split, what would you do? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fda714",
   "metadata": {},
   "source": [
    "Enter your answers below: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6f3fe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
