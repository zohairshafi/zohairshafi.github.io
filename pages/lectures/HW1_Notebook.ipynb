{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c44d5b",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "This homeworks will walk you through linear regression and regularization concepts we learned in class. \n",
    "\n",
    "**Due Date - Friday 30th January (11:59 PM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc16cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np  # arrays, vectorized math\n",
    "import pandas as pd  # tabular data handling (not heavily used here but students should familiarize themselves with this)\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "from sklearn.linear_model import LinearRegression  # ready-made linear regression\n",
    "\n",
    "rng = np.random.default_rng(42)  # reproducible randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a8537",
   "metadata": {},
   "source": [
    "## Synthetic Data\n",
    "We will create noisy linear data so we know the true relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not chnage this cell \n",
    "\n",
    "# Generate toy data\n",
    "# Set number of points to generate \n",
    "n = 40\n",
    "\n",
    "# Generate x axis data in the range of 0 to 5 \n",
    "# This is generated using a uniform distribution from numpy \n",
    "x = rng.uniform(0, 5, size = n)\n",
    "\n",
    "# Generate noise in the same shape from a Gaussian (normal) distribution\n",
    "noise = rng.normal(0, 2.0, size=n)\n",
    "uniform_noise = rng.uniform(-10, 10, size=n)\n",
    "\n",
    "# Define the \"true\" distribution\n",
    "y = 3 + (2 * (x ** 2)) + noise + uniform_noise\n",
    "\n",
    "# Some code to plot everything \n",
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "ax.scatter(x, y, alpha=0.7, label=\"Training Data\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Generated Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef401b9",
   "metadata": {},
   "source": [
    "## Matrix (Normal Equation) View\n",
    "Stack inputs into a matrix $X$ with a bias column of ones. The closed-form solution is\n",
    "$$\\theta = (X^\\top X)^{-1} X^\\top y,$$\n",
    "where $\\theta = [\\theta_0, \\theta_1, \\cdots \\theta_n]^\\top$. This is the same solution we derived in scalars, just written compactly.\n",
    "\n",
    "## Question 1 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119710d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############### Question 1 ####################\n",
    "###############################################\n",
    "\n",
    "# TODO: Solve for theta using the normal equation method equation shown above\n",
    "# Remember, you will need to account for the intercept / bias term. Use the np.column_stack \n",
    "# or the np.hstack() function to add a columns to your matrix X.\n",
    "# You can then use np.linalg.inv to compute the inverse\n",
    "# use the \"@\" operator to compute matrix multiplications\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############\n",
    "################################################\n",
    "\n",
    "X = None # Enter your code here\n",
    "theta = None # Enter your code here\n",
    "\n",
    "theta_0, theta_1 = theta\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "print(f\"Matrix slope (theta_1): {theta_1:.3f}\")\n",
    "print(f\"Matrix intercept (theta_0): {theta_0:.3f}\")\n",
    "\n",
    "# Plot the magnitudes of theta\n",
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "# Note that we use np.abs since we care only about the magnitude here and not the sign\n",
    "ax.bar(['theta_0', 'theta_1'], np.abs([theta_0, theta_1]))\n",
    "ax.set_ylabel('Magnitude')\n",
    "ax.set_title('Magnitude of Theta Parameters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646addc7",
   "metadata": {},
   "source": [
    "## Question 2 (5 points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "############### Question 2 ####################\n",
    "###############################################\n",
    "\n",
    "#TODO: Using your theta_0 and theta_1 from above, compute the predicted y values (y_hat). \n",
    "# You can compute the predicted values using the linear regression equation and the theta values you found above.\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "# Predict and evaluate\n",
    "# Define the learned model in terms of theta_0 and theta_1\n",
    "y_hat = None # Replace with your answer\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "\n",
    "# Compute and print loss \n",
    "mse_manual = np.mean((y - y_hat) ** 2)\n",
    "print(f\"Manual MSE: {mse_manual:.3f}\")\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "ax.scatter(x, y, alpha=0.6, label=\"observations\")\n",
    "ax.plot(np.sort(x), y_hat[np.argsort(x)], color=\"crimson\", label=\"manual fit\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Manual Least Squares Fit\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac4d7d8",
   "metadata": {},
   "source": [
    "## Question 3 (10 points)\n",
    "Lets make this a more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f642a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember you have a matrix X - lets look at its shape\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e7d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, now, lets add a few more features to X to see how that affects our model\n",
    "\n",
    "###############################################\n",
    "############### Question 2 ####################\n",
    "###############################################\n",
    "\n",
    "# TODO: Write a function to add x^2, x^3, all the way to x^10 as additional columns to X using np.column_stack or np.hstack\n",
    "# Then compute theta again.\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "def add_polynomial_features(x, degree):\n",
    "\n",
    "    '''\n",
    "    x : vector of shape (n,) representing the input feature. This is a np.array object\n",
    "    degree : integer representing the maximum polynomial degree to add as features\n",
    "    '''\n",
    "\n",
    "    # Initialize X with the original feature\n",
    "    X = None # Enter your code here - you can use something similat to Question 1\n",
    "    \n",
    "    # Then add polynomial features up to the given degree\n",
    "    # Enter your code here\n",
    "\n",
    "    return X\n",
    "\n",
    "X = add_polynomial_features(x, 10)\n",
    "\n",
    "# Now let us rerun the linear regression using your code above to find theta. \n",
    "theta = None # Enter your code here\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "print (\"Number of parameters: \", len(theta))\n",
    "print (f\"New theta values: {theta}\")\n",
    "\n",
    "# Plot the magnitudes of theta\n",
    "plt.figure(figsize = (6, 4))\n",
    "plt.bar(['theta_' + str(i) for i in range(len(theta))], np.abs(theta))\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Magnitude of Theta Parameters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0479c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's predict again using the new theta values. You can use the answer from Question 2 here. \n",
    "# Hint: Since you have multiple theta values now, try using the matrix form instead of the scalar form.\n",
    "\n",
    "################################################\n",
    "########## Write your answer here ##############    \n",
    "################################################\n",
    "\n",
    "y_hat = None # Enter your code here\n",
    "\n",
    "################################################\n",
    "########## End of your answer ##################\n",
    "################################################\n",
    "\n",
    "# Compute and print loss \n",
    "mse_manual = np.mean((y - y_hat) ** 2)\n",
    "print(f\"Manual MSE: {mse_manual:.3f}\")\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "ax.scatter(x, y, alpha=0.6, label=\"observations\")\n",
    "ax.plot(np.sort(x), y_hat[np.argsort(x)], color=\"crimson\", label=\"manual fit\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"Manual Least Squares Fit\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c492d07d",
   "metadata": {},
   "source": [
    "## Question 4 (5 points)\n",
    "Scroll up and check the MSE value you obtained in Question 2 with only linear features (x^1) and check the MSE model you obtained in Question 3 with polynomial features (x^1 to x^10). Which model do you think is better? Why? Look at the shape of the curves learned? Which model is better? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1075f27f",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:** Double click this cell to enter your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb84067",
   "metadata": {},
   "source": [
    "## Question 5 (10 points)\n",
    "We're going to see the impact of regularization in this question. \n",
    "\n",
    "Remember, regularization modifies the loss equation as \n",
    "\n",
    "$L(\\theta) = \\frac{1}{m} \\sum(Y - X\\theta)^2 + \\lambda \\|\\theta\\|^2$\n",
    "\n",
    "and the optimal $\\theta$ can be found using\n",
    "\n",
    "$\\theta = (X^\\top X + \\lambda I)^{-1} X^\\top y$\n",
    "\n",
    "Here, $\\lambda$ is a real scalar value and is the regularization hyper-parameter that controls how much you care about reducing the magnitudes of $\\theta$ and $I$ is the identity matrix. The term $\\lambda \\cdot I$ is *not* matrix multiplication. Why? Because $\\lambda$ is a scalar value and $I$ is the only matrix. So the resultant matrix will look like \n",
    "$\n",
    "\\lambda * \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    " 0 & 1 & 0 & 0 \\\\\n",
    " 0 & 0 & 1 & 0 \\\\\n",
    " 0 & 0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "\\lambda & 0 & 0 & 0 \\\\\n",
    " 0 & \\lambda & 0 & 0 \\\\\n",
    " 0 & 0 & \\lambda & 0 \\\\\n",
    " 0 & 0 & 0 & \\lambda\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacba19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first set our original data to \"train\" data \n",
    "X_train, y_train = X, y\n",
    "\n",
    "# Next, we will generate some test data to see how well our model generalizes\n",
    "x_test = rng.uniform(0, 5, size = n)\n",
    "\n",
    "# Here, we add additional polynomial features to the test data as well\n",
    "# using the function you wrote earlier\n",
    "X_test = add_polynomial_features(x_test, 10)\n",
    "\n",
    "\n",
    "# Next we're going to add noise, the same way we did for the training data\n",
    "noise = rng.normal(0, 1, size=n)\n",
    "uniform_noise = rng.uniform(-10, 10, size=n)\n",
    "\n",
    "# Finally, we define the \"test\" distribution\n",
    "y_test = 3 + (2 * (x_test ** 2)) + noise + uniform_noise\n",
    "\n",
    "# Here is a list of lambda values to try \n",
    "lambdas = [0.0, 0.1, 1.0, 10.0, 20.0, 50.0, 100.0, 200.0, 500.0, 1000.0, 10000.0]\n",
    "train_mse, test_mse = [], []\n",
    "\n",
    "# Here, we define the identity matrix\n",
    "I = np.identity(X_train.shape[1])\n",
    "\n",
    "# Iterate over each lambda value to see which lamda does best on test data\n",
    "# This is generally called a \"hyper parameter search\"\n",
    "for lam in lambdas:\n",
    "\n",
    "    ###############################################\n",
    "    ############### Question 5 ####################\n",
    "    ###############################################\n",
    "\n",
    "    # TODO: Compute theta using the equation for linear regression with L2 regularization (also called Ridge Regression) shown above\n",
    "    # Remember, here, we use the train set to train the model, i.e., only the train set will be used to compute theta. \n",
    "\n",
    "    ################################################\n",
    "    ########## Write your answer here ##############    \n",
    "    ################################################\n",
    "\n",
    "    theta = None # Enter your code here\n",
    "\n",
    "    \n",
    "    # Now use your code from Question 3 to compute the predicted outputs for both the train and test sets\n",
    "    # using the theta you have just found above\n",
    "    y_pred = None # Enter your code here\n",
    "    y_test_pred = None # Enter your code here\n",
    "\n",
    "    ################################################\n",
    "    ########## End of your answer ##################\n",
    "    ################################################\n",
    "    \n",
    "    # Using the predictions above, we now compute the mean squared errors for both the train and test sets\n",
    "    train_mse.append(np.mean((y_train - y_pred) ** 2))\n",
    "    test_mse.append(np.mean((y_test - y_test_pred) ** 2))\n",
    "\n",
    "\n",
    "    # As before, we plot the magnitudes of theta\n",
    "    plt.figure(figsize = (6, 4))\n",
    "    plt.bar(['theta_' + str(i) for i in range(len(theta))], np.abs(theta))\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.title(f'Magnitude of Theta Parameters ($\\\\lambda={lam}$)')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(lambdas, train_mse, marker='o', label='Train MSE')\n",
    "ax.plot(lambdas, test_mse, marker='o', label='Test MSE')\n",
    "ax.set_xscale('symlog')\n",
    "ax.set_xlabel('lambda')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_title('Mean Squared Error vs Lambda')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame({'Lambda': lambdas, 'Train MSE': train_mse, 'Test MSE': test_mse})\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4826840",
   "metadata": {},
   "source": [
    "## Question 6 (2 points each - total 10 points)\n",
    "What can you tell about regularization from all of the plots above? Specifically:\n",
    "\n",
    "(a) What changes as $\\lambda$ goes up in terms of learned parameters? \n",
    "\n",
    "(b) What changes as $\\lambda$ goes up in terms of mean squared error? \n",
    "\n",
    "(c) Does the model overfit at certain values of $\\lambda$? If so, which?\n",
    "\n",
    "(d) Does the model underfit at certain values of $\\lambda$? If so, which?\n",
    "\n",
    "(e) From the table, is there an optimal value of $\\lambda$ that hits a good trade off between underfitting and overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b972aa2",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "(a) \n",
    "\n",
    "(b)\n",
    "\n",
    "(c)\n",
    "\n",
    "(d)\n",
    "\n",
    "(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54560898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
